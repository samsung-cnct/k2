
- set_fact:
    cluster: "{{ a_cluster }}"

- set_fact:
    aws_region: "{{ cluster.providerConfig.region }}"
    kubeconfig: "{{ config_base | expanduser }}/{{ cluster.name }}/admin.kubeconfig"

- name: Set Expected Master Node Count
  vars:
    test_case: "nodePools[?name=='master'].count"
  set_fact:
    expected_master_node_count: "{{ cluster|json_query(test_case)|first}}"

- name: Collect Master nodes
  shell: kubectl --kubeconfig={{ kubeconfig }} get nodes -l nodepool=master -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}'
  register: master_node_names

- name: Gather EC2 facts
  ec2_remote_facts:
    region: "{{ cluster.providerConfig.region }}"
    aws_access_key: "{{ cluster.providerConfig.authentication.accessKey or omit }}"
    aws_secret_key: "{{ cluster.providerConfig.authentication.accessSecret or omit }}"
    profile: "{{ cluster.providerConfig.authentication.credentialsProfile or omit }}"
  register: instance_info
  ignore_errors: yes

- name: Create dict with node names and instance ids
  set_fact:
    names_and_instance_ids: "{{ names_and_instance_ids|default({}) | combine( {item.0: item.1} )  }}"
  with_together:
    - "{{ instance_info.instances|map(attribute='private_dns_name')|list }}"
    - "{{ instance_info.instances|map(attribute='id')|list }}"
  when: item.0 in master_node_names.stdout_lines

- name: Delete and Terminate Master Nodes
  set_fact:
    node_destruction: "{{ item.key |delete_and_terminate_node_filter(item.value, expected_master_node_count, kubeconfig, aws_region) }}"
  with_dict: "{{ names_and_instance_ids }}"
  failed_when: node_destruction == False
